ğŸ§  QANDA: Chat with Any Webpage Using LLMs
This project enables users to load any webpage, convert its content into embeddings, and chat with it using LLMs. You can interact via a Streamlit interface or through a FastAPI backend.

ğŸš€ Features
ğŸŒ Load and parse webpage content (e.g., Gutenberg books)

ğŸ§© Chunk text for embedding

ğŸ” Store in Chroma vector DB

ğŸ¤– Ask questions with RAG (Retrieval-Augmented Generation) using Google Gemini 1.5 Flash

ğŸ–¥ï¸ Dual Interface:

app_streamlit.py for interactive Streamlit app

FastAPI (main.py + routes.py) for backend service

ğŸ“‚ Project Structure
bash
Copy
Edit
QANDA/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py            # FastAPI entry point
â”‚   â”œâ”€â”€ routes.py          # API endpoints
â”‚   â”œâ”€â”€ pipeline.py        # Core logic (load, chunk, embed, query)
â”‚
â”œâ”€â”€ chroma_db/             # Chroma vector DB persistence
â”œâ”€â”€ app_streamlit.py       # Streamlit app
â”œâ”€â”€ chunks.py              # Text chunking logic (modular)
â”œâ”€â”€ embeddings.py          # Embedding logic (Google Generative AI)
â”œâ”€â”€ llm.py                 # Gemini LLM prompt and chain
â”œâ”€â”€ load_data.py           # Web loader module
â”œâ”€â”€ prompts.py             # Prompt templates
â”œâ”€â”€ notebook.ipynb         # (Optional) Development notebook
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env                   # Google API keys
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
ğŸ§ª Installation
1. Clone the repo
bash
Copy
Edit
git clone https://github.com/your-username/QANDA.git
cd QANDA
2. Set up a virtual environment
bash
Copy
Edit
python -m venv QandAvenv
# Activate it:
# On Windows:
QandAvenv\Scripts\activate
# On macOS/Linux:
source QandAvenv/bin/activate
3. Install dependencies
bash
Copy
Edit
pip install -r requirements.txt
ğŸ” Environment Setup
Create a .env file with your Google Generative AI API Key:

ini
Copy
Edit
GOOGLE_API_KEY=your_google_genai_key_here
ğŸ–¥ï¸ Streamlit UI
Run the Streamlit interface:

bash
Copy
Edit
streamlit run app_streamlit.py
Usage
Enter a webpage URL (e.g., a Project Gutenberg .txt link)

Ask natural language questions about the content

View accurate, context-based answers

âš™ï¸ FastAPI Backend
Run the server
bash
Copy
Edit
uvicorn app.main:app --reload
Endpoints
POST /load
Loads and indexes the webpage content:

json
Copy
Edit
{
  "url": "https://www.gutenberg.org/cache/epub/100/pg100.txt"
}
POST /ask
Ask questions about the loaded content:

json
Copy
Edit
{
  "question": "Who is Hamlet?"
}
Returns:

json
Copy
Edit
{
  "answer": "Hamlet is the Prince of Denmark...",
  "sources": ["<snippet from the text>"]
}
ğŸ“¦ Dependencies
streamlit

fastapi

uvicorn

langchain

langchain_chroma

langchain_google_genai

chromadb

python-dotenv

pydantic

ğŸ“Œ Tips
Ensure your Google API key has access to both embedding-001 and gemini-1.5-flash.

Webpage parsing is handled by langchain_community.document_loaders.WebBaseLoader.

ğŸ“ˆ Roadmap
âœ… Dual interface (Streamlit + FastAPI)

ğŸš§ Support PDFs, YouTube transcripts

ğŸš€ Deployment via Hugging Face Spaces or Render

ğŸ§‘â€ğŸ’» Author
Prasadraj â€” Built with â¤ï¸ using LangChain + Gemini